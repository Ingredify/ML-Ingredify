{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2999036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_df = pd.read_csv(\"recipes_data.csv\", nrows=1000)\n",
    "# recipe_df.to_csv(\"recipes_1000.csv\", index=False)\n",
    "\n",
    "recipe_df = pd.read_csv(\"recipes_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6384bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>NER</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"bite size shredded rice biscuits\", \"vanilla\"...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"cream of mushroom soup\", \"beef\", \"sour cream...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"frozen corn\", \"pepper\", \"cream cheese\", \"gar...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=897570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"chicken gravy\", \"cream of mushroom soup\", \"c...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=659239</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"graham cracker crumbs\", \"powdered sugar\", \"p...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Baked Beans</td>\n",
       "      <td>[\"3 (1 lb.) cans pork and beans\", \"1/2 c. bell...</td>\n",
       "      <td>[\"Cook onions and bell pepper in oil until oni...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=775763</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"oil\", \"bell pepper\", \"black pepper\", \"brown ...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sweet-N-Sour Chicken</td>\n",
       "      <td>[\"2 c. diced cooked chicken\", \"2 Tbsp. shorten...</td>\n",
       "      <td>[\"Saute onion in 2 tablespoons shortening.\", \"...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=228506</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"vinegar\", \"ginger\", \"soy sauce\", \"shortening...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>[\"8 to 10 juicy oranges, peeled and diced\", \"1...</td>\n",
       "      <td>[\"Combine all ingredients. Chill overnight.\", ...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=342478</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"sugar\", \"pecans\", \"moist coconut\", \"cherries...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Crazy Peanut Butter Cookies</td>\n",
       "      <td>[\"1 c. creamy peanut butter\", \"1 c. sugar\", \"1...</td>\n",
       "      <td>[\"Mix together and roll into balls; flatten wi...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=892363</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"egg\", \"peanut butter\", \"sugar\"]</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Brickle Bars</td>\n",
       "      <td>[\"1 box yellow cake mix\", \"2 eggs\", \"1/3 c. so...</td>\n",
       "      <td>[\"Mix together with a fork:\", \"cake mix, 1 egg...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=351194</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"eggs\", \"pecans\", \"margarine\", \"milk\", \"yello...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0           No-Bake Nut Cookies   \n",
       "1         Jewell Ball'S Chicken   \n",
       "2                   Creamy Corn   \n",
       "3                 Chicken Funny   \n",
       "4          Reeses Cups(Candy)     \n",
       "..                          ...   \n",
       "95                  Baked Beans   \n",
       "96         Sweet-N-Sour Chicken   \n",
       "97                     Ambrosia   \n",
       "98  Crazy Peanut Butter Cookies   \n",
       "99                 Brickle Bars   \n",
       "\n",
       "                                          ingredients  \\\n",
       "0   [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
       "1   [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2   [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
       "3   [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
       "4   [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
       "..                                                ...   \n",
       "95  [\"3 (1 lb.) cans pork and beans\", \"1/2 c. bell...   \n",
       "96  [\"2 c. diced cooked chicken\", \"2 Tbsp. shorten...   \n",
       "97  [\"8 to 10 juicy oranges, peeled and diced\", \"1...   \n",
       "98  [\"1 c. creamy peanut butter\", \"1 c. sugar\", \"1...   \n",
       "99  [\"1 box yellow cake mix\", \"2 eggs\", \"1/3 c. so...   \n",
       "\n",
       "                                           directions  \\\n",
       "0   [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
       "1   [\"Place chipped beef on bottom of baking dish....   \n",
       "2   [\"In a slow cooker, combine all ingredients. C...   \n",
       "3   [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
       "4   [\"Combine first four ingredients and press in ...   \n",
       "..                                                ...   \n",
       "95  [\"Cook onions and bell pepper in oil until oni...   \n",
       "96  [\"Saute onion in 2 tablespoons shortening.\", \"...   \n",
       "97  [\"Combine all ingredients. Chill overnight.\", ...   \n",
       "98  [\"Mix together and roll into balls; flatten wi...   \n",
       "99  [\"Mix together with a fork:\", \"cake mix, 1 egg...   \n",
       "\n",
       "                                               link    source  \\\n",
       "0    www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
       "1   www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
       "2    www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
       "3   www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
       "4   www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
       "..                                              ...       ...   \n",
       "95  www.cookbooks.com/Recipe-Details.aspx?id=775763  Gathered   \n",
       "96  www.cookbooks.com/Recipe-Details.aspx?id=228506  Gathered   \n",
       "97  www.cookbooks.com/Recipe-Details.aspx?id=342478  Gathered   \n",
       "98  www.cookbooks.com/Recipe-Details.aspx?id=892363  Gathered   \n",
       "99  www.cookbooks.com/Recipe-Details.aspx?id=351194  Gathered   \n",
       "\n",
       "                                                  NER               site  \n",
       "0   [\"bite size shredded rice biscuits\", \"vanilla\"...  www.cookbooks.com  \n",
       "1   [\"cream of mushroom soup\", \"beef\", \"sour cream...  www.cookbooks.com  \n",
       "2   [\"frozen corn\", \"pepper\", \"cream cheese\", \"gar...  www.cookbooks.com  \n",
       "3   [\"chicken gravy\", \"cream of mushroom soup\", \"c...  www.cookbooks.com  \n",
       "4   [\"graham cracker crumbs\", \"powdered sugar\", \"p...  www.cookbooks.com  \n",
       "..                                                ...                ...  \n",
       "95  [\"oil\", \"bell pepper\", \"black pepper\", \"brown ...  www.cookbooks.com  \n",
       "96  [\"vinegar\", \"ginger\", \"soy sauce\", \"shortening...  www.cookbooks.com  \n",
       "97  [\"sugar\", \"pecans\", \"moist coconut\", \"cherries...  www.cookbooks.com  \n",
       "98                  [\"egg\", \"peanut butter\", \"sugar\"]  www.cookbooks.com  \n",
       "99  [\"eggs\", \"pecans\", \"margarine\", \"milk\", \"yello...  www.cookbooks.com  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596b6469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>link</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n",
       "      <td>[\"bite size shredded rice biscuits\", \"vanilla\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n",
       "      <td>[\"cream of mushroom soup\", \"beef\", \"sour cream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n",
       "      <td>[\"frozen corn\", \"pepper\", \"cream cheese\", \"gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=897570</td>\n",
       "      <td>[\"chicken gravy\", \"cream of mushroom soup\", \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=659239</td>\n",
       "      <td>[\"graham cracker crumbs\", \"powdered sugar\", \"p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Baked Beans</td>\n",
       "      <td>[\"3 (1 lb.) cans pork and beans\", \"1/2 c. bell...</td>\n",
       "      <td>[\"Cook onions and bell pepper in oil until oni...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=775763</td>\n",
       "      <td>[\"oil\", \"bell pepper\", \"black pepper\", \"brown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sweet-N-Sour Chicken</td>\n",
       "      <td>[\"2 c. diced cooked chicken\", \"2 Tbsp. shorten...</td>\n",
       "      <td>[\"Saute onion in 2 tablespoons shortening.\", \"...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=228506</td>\n",
       "      <td>[\"vinegar\", \"ginger\", \"soy sauce\", \"shortening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>[\"8 to 10 juicy oranges, peeled and diced\", \"1...</td>\n",
       "      <td>[\"Combine all ingredients. Chill overnight.\", ...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=342478</td>\n",
       "      <td>[\"sugar\", \"pecans\", \"moist coconut\", \"cherries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Crazy Peanut Butter Cookies</td>\n",
       "      <td>[\"1 c. creamy peanut butter\", \"1 c. sugar\", \"1...</td>\n",
       "      <td>[\"Mix together and roll into balls; flatten wi...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=892363</td>\n",
       "      <td>[\"egg\", \"peanut butter\", \"sugar\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Brickle Bars</td>\n",
       "      <td>[\"1 box yellow cake mix\", \"2 eggs\", \"1/3 c. so...</td>\n",
       "      <td>[\"Mix together with a fork:\", \"cake mix, 1 egg...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=351194</td>\n",
       "      <td>[\"eggs\", \"pecans\", \"margarine\", \"milk\", \"yello...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0           No-Bake Nut Cookies   \n",
       "1         Jewell Ball'S Chicken   \n",
       "2                   Creamy Corn   \n",
       "3                 Chicken Funny   \n",
       "4          Reeses Cups(Candy)     \n",
       "..                          ...   \n",
       "95                  Baked Beans   \n",
       "96         Sweet-N-Sour Chicken   \n",
       "97                     Ambrosia   \n",
       "98  Crazy Peanut Butter Cookies   \n",
       "99                 Brickle Bars   \n",
       "\n",
       "                                          ingredients  \\\n",
       "0   [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
       "1   [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2   [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
       "3   [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
       "4   [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
       "..                                                ...   \n",
       "95  [\"3 (1 lb.) cans pork and beans\", \"1/2 c. bell...   \n",
       "96  [\"2 c. diced cooked chicken\", \"2 Tbsp. shorten...   \n",
       "97  [\"8 to 10 juicy oranges, peeled and diced\", \"1...   \n",
       "98  [\"1 c. creamy peanut butter\", \"1 c. sugar\", \"1...   \n",
       "99  [\"1 box yellow cake mix\", \"2 eggs\", \"1/3 c. so...   \n",
       "\n",
       "                                           directions  \\\n",
       "0   [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
       "1   [\"Place chipped beef on bottom of baking dish....   \n",
       "2   [\"In a slow cooker, combine all ingredients. C...   \n",
       "3   [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
       "4   [\"Combine first four ingredients and press in ...   \n",
       "..                                                ...   \n",
       "95  [\"Cook onions and bell pepper in oil until oni...   \n",
       "96  [\"Saute onion in 2 tablespoons shortening.\", \"...   \n",
       "97  [\"Combine all ingredients. Chill overnight.\", ...   \n",
       "98  [\"Mix together and roll into balls; flatten wi...   \n",
       "99  [\"Mix together with a fork:\", \"cake mix, 1 egg...   \n",
       "\n",
       "                                               link  \\\n",
       "0    www.cookbooks.com/Recipe-Details.aspx?id=44874   \n",
       "1   www.cookbooks.com/Recipe-Details.aspx?id=699419   \n",
       "2    www.cookbooks.com/Recipe-Details.aspx?id=10570   \n",
       "3   www.cookbooks.com/Recipe-Details.aspx?id=897570   \n",
       "4   www.cookbooks.com/Recipe-Details.aspx?id=659239   \n",
       "..                                              ...   \n",
       "95  www.cookbooks.com/Recipe-Details.aspx?id=775763   \n",
       "96  www.cookbooks.com/Recipe-Details.aspx?id=228506   \n",
       "97  www.cookbooks.com/Recipe-Details.aspx?id=342478   \n",
       "98  www.cookbooks.com/Recipe-Details.aspx?id=892363   \n",
       "99  www.cookbooks.com/Recipe-Details.aspx?id=351194   \n",
       "\n",
       "                                                  NER  \n",
       "0   [\"bite size shredded rice biscuits\", \"vanilla\"...  \n",
       "1   [\"cream of mushroom soup\", \"beef\", \"sour cream...  \n",
       "2   [\"frozen corn\", \"pepper\", \"cream cheese\", \"gar...  \n",
       "3   [\"chicken gravy\", \"cream of mushroom soup\", \"c...  \n",
       "4   [\"graham cracker crumbs\", \"powdered sugar\", \"p...  \n",
       "..                                                ...  \n",
       "95  [\"oil\", \"bell pepper\", \"black pepper\", \"brown ...  \n",
       "96  [\"vinegar\", \"ginger\", \"soy sauce\", \"shortening...  \n",
       "97  [\"sugar\", \"pecans\", \"moist coconut\", \"cherries...  \n",
       "98                  [\"egg\", \"peanut butter\", \"sugar\"]  \n",
       "99  [\"eggs\", \"pecans\", \"margarine\", \"milk\", \"yello...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_df = recipe_df.drop(columns=[\"source\", \"site\"])\n",
    "recipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac59aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gagal parsing: Expecting ',' delimiter: line 1 column 22 (char 21)\n",
      "['bite size shredded rice biscuits', 'vanilla', 'brown sugar', 'nuts', 'milk', 'butter']\n",
      "bite size shredded rice biscuits, vanilla, brown sugar, nuts, milk, butter\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk bersihkan dan konversi string list menjadi list Python asli\n",
    "def clean_and_parse_json_list(x):\n",
    "    if isinstance(x, str):\n",
    "        # Ganti double double-quote menjadi satu double-quote\n",
    "        x = x.replace('\"\"', '\"')\n",
    "\n",
    "        # Kadang ada tanda kutip tunggal yang harus diganti ke double quotes\n",
    "        # Untuk data kamu, coba replace tanda kutip tunggal di awal dan akhir\n",
    "        if x.startswith(\"'\") and x.endswith(\"'\"):\n",
    "            x = x[1:-1]\n",
    "\n",
    "        # Pastikan tanda kutip didalam string di-escape dengan benar\n",
    "        try:\n",
    "            return json.loads(x)\n",
    "        except json.JSONDecodeError:\n",
    "            # Kalau gagal, coba raw string fix (misalnya escape manual)\n",
    "            x = x.replace('\\\\\"', '\"').replace('\\\\\\'', '\\'')\n",
    "            try:\n",
    "                return json.loads(x)\n",
    "            except Exception as e:\n",
    "                print(\"Gagal parsing:\", e)\n",
    "                # fallback return string asli kalau error parsing\n",
    "                return x\n",
    "    return x\n",
    "\n",
    "# Terapkan hanya ke kolom yang berbentuk list dalam string\n",
    "for col in [\"ingredients\", \"directions\", \"NER\"]:\n",
    "    recipe_df[col] = recipe_df[col].apply(clean_and_parse_json_list)\n",
    "\n",
    "# Contoh cek hasil parsing kolom NER baris pertama\n",
    "print(recipe_df[\"NER\"].iloc[0])\n",
    "\n",
    "# Kalau mau convert kolom NER jadi string (optional, misal untuk model input string)\n",
    "recipe_df[\"NER_str\"] = recipe_df[\"NER\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else \"\")\n",
    "\n",
    "# Cek hasilnya\n",
    "print(recipe_df[\"NER_str\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5863eff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>Brown Rice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1</td>\n",
       "      <td>Three Bean Salad</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_1</td>\n",
       "      <td>Dot'S Civil War Cake</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1</td>\n",
       "      <td>Chocolate Mint Bars</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_1</td>\n",
       "      <td>Fruit Pizza</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>user_5000</td>\n",
       "      <td>Taco Dip</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>user_5000</td>\n",
       "      <td>Sausage Balls</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>user_5000</td>\n",
       "      <td>Chicken Roll-Ups</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>user_5000</td>\n",
       "      <td>Cheeseburger Potato Soup</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>user_5000</td>\n",
       "      <td>Fast Real Good Fudge</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id                     title  rating\n",
       "0          user_1                Brown Rice       4\n",
       "1          user_1          Three Bean Salad       4\n",
       "2          user_1      Dot'S Civil War Cake       5\n",
       "3          user_1       Chocolate Mint Bars       4\n",
       "4          user_1               Fruit Pizza       4\n",
       "...           ...                       ...     ...\n",
       "249995  user_5000                  Taco Dip       4\n",
       "249996  user_5000             Sausage Balls       2\n",
       "249997  user_5000          Chicken Roll-Ups       4\n",
       "249998  user_5000  Cheeseburger Potato Soup       4\n",
       "249999  user_5000      Fast Real Good Fudge       4\n",
       "\n",
       "[250000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buat user dan resep\n",
    "recipes = recipe_df[\"title\"].unique()\n",
    "num_users = 5000\n",
    "user_ids = [f\"user_{i+1}\" for i in range(num_users)]\n",
    "\n",
    "# Bangun interactions\n",
    "interactions = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for user in user_ids:\n",
    "    liked = np.random.choice(recipes, size=50, replace=False)\n",
    "    for recipe in liked:\n",
    "        interactions.append({\"user_id\": user, \"title\": recipe})\n",
    "\n",
    "interaction_df = pd.DataFrame(interactions)\n",
    "\n",
    "# Atur ulang seed untuk rating\n",
    "np.random.seed(42)\n",
    "\n",
    "# Jumlah total interaksi\n",
    "n = len(interaction_df)\n",
    "\n",
    "# Buat 80% rating > 3 (yaitu: 4 atau 5)\n",
    "high_ratings = np.random.randint(4, 6, size=int(n * 0.9))  # 4 or 5\n",
    "# Buat 20% rating <= 3 (1, 2, atau 3)\n",
    "low_ratings = np.random.randint(1, 4, size=n - len(high_ratings))\n",
    "\n",
    "# Gabungkan dan acak\n",
    "all_ratings = np.concatenate([high_ratings, low_ratings])\n",
    "np.random.shuffle(all_ratings)\n",
    "\n",
    "# Masukkan ke DataFrame\n",
    "interaction_df[\"rating\"] = all_ratings\n",
    "\n",
    "# Tampilkan tabel\n",
    "interaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b799d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "261/261 [==============================] - 25s 92ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0098 - factorized_top_k/top_5_categorical_accuracy: 0.0450 - factorized_top_k/top_10_categorical_accuracy: 0.0843 - factorized_top_k/top_50_categorical_accuracy: 0.3977 - factorized_top_k/top_100_categorical_accuracy: 0.9120 - root_mean_squared_error: 1.6115 - loss: 5082.1621 - regularization_loss: 0.0000e+00 - total_loss: 5082.1621 - val_factorized_top_k/top_1_categorical_accuracy: 0.0044 - val_factorized_top_k/top_5_categorical_accuracy: 0.0392 - val_factorized_top_k/top_10_categorical_accuracy: 0.0842 - val_factorized_top_k/top_50_categorical_accuracy: 0.4728 - val_factorized_top_k/top_100_categorical_accuracy: 0.9996 - val_root_mean_squared_error: 0.9498 - val_loss: 1955.7428 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1955.7428\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 23s 89ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0065 - factorized_top_k/top_5_categorical_accuracy: 0.0503 - factorized_top_k/top_10_categorical_accuracy: 0.1072 - factorized_top_k/top_50_categorical_accuracy: 0.5382 - factorized_top_k/top_100_categorical_accuracy: 0.9949 - root_mean_squared_error: 0.9570 - loss: 5074.6713 - regularization_loss: 0.0000e+00 - total_loss: 5074.6713 - val_factorized_top_k/top_1_categorical_accuracy: 0.0042 - val_factorized_top_k/top_5_categorical_accuracy: 0.0330 - val_factorized_top_k/top_10_categorical_accuracy: 0.0751 - val_factorized_top_k/top_50_categorical_accuracy: 0.4648 - val_factorized_top_k/top_100_categorical_accuracy: 0.9948 - val_root_mean_squared_error: 0.9715 - val_loss: 1959.6106 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1959.6106\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 24s 90ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0071 - factorized_top_k/top_5_categorical_accuracy: 0.0745 - factorized_top_k/top_10_categorical_accuracy: 0.1517 - factorized_top_k/top_50_categorical_accuracy: 0.6255 - factorized_top_k/top_100_categorical_accuracy: 0.9972 - root_mean_squared_error: 1.0627 - loss: 5026.1159 - regularization_loss: 0.0000e+00 - total_loss: 5026.1159 - val_factorized_top_k/top_1_categorical_accuracy: 0.0024 - val_factorized_top_k/top_5_categorical_accuracy: 0.0268 - val_factorized_top_k/top_10_categorical_accuracy: 0.0654 - val_factorized_top_k/top_50_categorical_accuracy: 0.4472 - val_factorized_top_k/top_100_categorical_accuracy: 0.9927 - val_root_mean_squared_error: 1.0249 - val_loss: 1983.4283 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1983.4283\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 24s 91ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0083 - factorized_top_k/top_5_categorical_accuracy: 0.0929 - factorized_top_k/top_10_categorical_accuracy: 0.1837 - factorized_top_k/top_50_categorical_accuracy: 0.6735 - factorized_top_k/top_100_categorical_accuracy: 0.9978 - root_mean_squared_error: 1.1277 - loss: 4986.9106 - regularization_loss: 0.0000e+00 - total_loss: 4986.9106 - val_factorized_top_k/top_1_categorical_accuracy: 0.0017 - val_factorized_top_k/top_5_categorical_accuracy: 0.0236 - val_factorized_top_k/top_10_categorical_accuracy: 0.0589 - val_factorized_top_k/top_50_categorical_accuracy: 0.4260 - val_factorized_top_k/top_100_categorical_accuracy: 0.9943 - val_root_mean_squared_error: 1.0779 - val_loss: 2008.5172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2008.5172\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 24s 90ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0085 - factorized_top_k/top_5_categorical_accuracy: 0.1007 - factorized_top_k/top_10_categorical_accuracy: 0.1976 - factorized_top_k/top_50_categorical_accuracy: 0.6989 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - root_mean_squared_error: 1.1450 - loss: 4964.5230 - regularization_loss: 0.0000e+00 - total_loss: 4964.5230 - val_factorized_top_k/top_1_categorical_accuracy: 0.0015 - val_factorized_top_k/top_5_categorical_accuracy: 0.0192 - val_factorized_top_k/top_10_categorical_accuracy: 0.0498 - val_factorized_top_k/top_50_categorical_accuracy: 0.4110 - val_factorized_top_k/top_100_categorical_accuracy: 0.9943 - val_root_mean_squared_error: 1.1616 - val_loss: 2037.2164 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2037.2164\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 24s 90ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0084 - factorized_top_k/top_5_categorical_accuracy: 0.1049 - factorized_top_k/top_10_categorical_accuracy: 0.2065 - factorized_top_k/top_50_categorical_accuracy: 0.7153 - factorized_top_k/top_100_categorical_accuracy: 0.9987 - root_mean_squared_error: 1.1434 - loss: 4950.8376 - regularization_loss: 0.0000e+00 - total_loss: 4950.8376 - val_factorized_top_k/top_1_categorical_accuracy: 8.6000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0144 - val_factorized_top_k/top_10_categorical_accuracy: 0.0437 - val_factorized_top_k/top_50_categorical_accuracy: 0.3927 - val_factorized_top_k/top_100_categorical_accuracy: 0.9920 - val_root_mean_squared_error: 1.2644 - val_loss: 2078.8237 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2078.8237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x296b43c55a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================\n",
    "# 1. Data Preparation\n",
    "# ====================\n",
    "interaction_df[\"user_id\"] = interaction_df[\"user_id\"].astype(str)\n",
    "interaction_df[\"title\"] = interaction_df[\"title\"].astype(str)\n",
    "\n",
    "unique_user_ids = interaction_df[\"user_id\"].unique()\n",
    "unique_titles = interaction_df[\"title\"].unique()\n",
    "\n",
    "train_df, test_df = train_test_split(interaction_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": train_df[\"user_id\"].values,\n",
    "    \"title\": train_df[\"title\"].values,\n",
    "    \"rating\": train_df[\"rating\"].values\n",
    "}).shuffle(100).batch(768).cache()\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": test_df[\"user_id\"].values,\n",
    "    \"title\": test_df[\"title\"].values,\n",
    "    \"rating\": test_df[\"rating\"].values,\n",
    "}).batch(512)\n",
    "\n",
    "recipe_dataset = tf.data.Dataset.from_tensor_slices(unique_titles)\n",
    "\n",
    "# ====================\n",
    "# 2. Lookup Layers\n",
    "# ====================\n",
    "user_lookup = tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None)\n",
    "title_lookup = tf.keras.layers.StringLookup(vocabulary=unique_titles, mask_token=None)\n",
    "\n",
    "# ====================\n",
    "# 3. User & Item Model\n",
    "# ====================\n",
    "embedding_dim = 512\n",
    "\n",
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            user_lookup,\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dim),\n",
    "            tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(embedding_dim)\n",
    "        ])\n",
    "    def call(self, inputs):\n",
    "        return self.user_embedding(inputs)\n",
    "\n",
    "class ItemModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            title_lookup,\n",
    "            tf.keras.layers.Embedding(len(unique_titles) + 1, embedding_dim),\n",
    "            tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(embedding_dim)\n",
    "        ])\n",
    "    def call(self, inputs):\n",
    "        return self.item_embedding(inputs)\n",
    "\n",
    "# ====================\n",
    "# 4. Combined Model with Metrics\n",
    "# ====================\n",
    "class RecipeModel(tfrs.Model):\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        self.retrieval_task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=recipe_dataset.batch(128).map(lambda x: (x, item_model(x)))\n",
    "            )\n",
    "        )\n",
    "        self.rating_task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        item_embeddings = self.item_model(features[\"title\"])\n",
    "\n",
    "        rating_predictions = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=features[\"rating\"],\n",
    "            predictions=rating_predictions\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, item_embeddings)\n",
    "\n",
    "        return rating_loss + retrieval_loss\n",
    "\n",
    "# ====================\n",
    "# 5. Training\n",
    "# ====================\n",
    "user_model = UserModel()\n",
    "item_model = ItemModel()\n",
    "model = RecipeModel(user_model, item_model)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0005))\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ====================\n",
    "# 6. Build Recommendation Index\n",
    "# ====================\n",
    "def map_title_to_embedding(title):\n",
    "    embedding = item_model(tf.expand_dims(title, 0))\n",
    "    return tf.expand_dims(title, 0), embedding\n",
    "\n",
    "indexed_dataset = recipe_dataset.map(map_title_to_embedding)\n",
    "\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(indexed_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1b2357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "261/261 [==============================] - 29s 103ms/step - factorized_top_k/top_1_categorical_accuracy: 0.4979 - factorized_top_k/top_5_categorical_accuracy: 0.5788 - factorized_top_k/top_10_categorical_accuracy: 0.6347 - factorized_top_k/top_50_categorical_accuracy: 0.8635 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 5078.4383 - regularization_loss: 8.3045e-07 - total_loss: 5078.4383 - val_factorized_top_k/top_1_categorical_accuracy: 0.0047 - val_factorized_top_k/top_5_categorical_accuracy: 0.0383 - val_factorized_top_k/top_10_categorical_accuracy: 0.0847 - val_factorized_top_k/top_50_categorical_accuracy: 0.4712 - val_factorized_top_k/top_100_categorical_accuracy: 0.9936 - val_loss: 1954.5615 - val_regularization_loss: 7.8559e-07 - val_total_loss: 1954.5615\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 39s 151ms/step - factorized_top_k/top_1_categorical_accuracy: 0.5440 - factorized_top_k/top_5_categorical_accuracy: 0.6405 - factorized_top_k/top_10_categorical_accuracy: 0.6947 - factorized_top_k/top_50_categorical_accuracy: 0.8857 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 5077.4022 - regularization_loss: 8.6376e-07 - total_loss: 5077.4022 - val_factorized_top_k/top_1_categorical_accuracy: 0.0045 - val_factorized_top_k/top_5_categorical_accuracy: 0.0378 - val_factorized_top_k/top_10_categorical_accuracy: 0.0814 - val_factorized_top_k/top_50_categorical_accuracy: 0.4687 - val_factorized_top_k/top_100_categorical_accuracy: 0.9968 - val_loss: 1954.3563 - val_regularization_loss: 9.1413e-07 - val_total_loss: 1954.3563\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 39s 151ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2425 - factorized_top_k/top_5_categorical_accuracy: 0.3634 - factorized_top_k/top_10_categorical_accuracy: 0.4356 - factorized_top_k/top_50_categorical_accuracy: 0.7653 - factorized_top_k/top_100_categorical_accuracy: 0.9981 - loss: 5049.0354 - regularization_loss: 9.9551e-07 - total_loss: 5049.0354 - val_factorized_top_k/top_1_categorical_accuracy: 0.0035 - val_factorized_top_k/top_5_categorical_accuracy: 0.0324 - val_factorized_top_k/top_10_categorical_accuracy: 0.0736 - val_factorized_top_k/top_50_categorical_accuracy: 0.4573 - val_factorized_top_k/top_100_categorical_accuracy: 0.9958 - val_loss: 1963.8427 - val_regularization_loss: 1.0988e-06 - val_total_loss: 1963.8427\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 40s 152ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0129 - factorized_top_k/top_5_categorical_accuracy: 0.0851 - factorized_top_k/top_10_categorical_accuracy: 0.1644 - factorized_top_k/top_50_categorical_accuracy: 0.6312 - factorized_top_k/top_100_categorical_accuracy: 0.9971 - loss: 5013.6918 - regularization_loss: 1.1106e-06 - total_loss: 5013.6918 - val_factorized_top_k/top_1_categorical_accuracy: 0.0026 - val_factorized_top_k/top_5_categorical_accuracy: 0.0290 - val_factorized_top_k/top_10_categorical_accuracy: 0.0686 - val_factorized_top_k/top_50_categorical_accuracy: 0.4464 - val_factorized_top_k/top_100_categorical_accuracy: 0.9962 - val_loss: 1991.9083 - val_regularization_loss: 1.1714e-06 - val_total_loss: 1991.9083\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 39s 150ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0112 - factorized_top_k/top_5_categorical_accuracy: 0.0908 - factorized_top_k/top_10_categorical_accuracy: 0.1756 - factorized_top_k/top_50_categorical_accuracy: 0.6517 - factorized_top_k/top_100_categorical_accuracy: 0.9975 - loss: 4993.7540 - regularization_loss: 1.1547e-06 - total_loss: 4993.7540 - val_factorized_top_k/top_1_categorical_accuracy: 0.0020 - val_factorized_top_k/top_5_categorical_accuracy: 0.0242 - val_factorized_top_k/top_10_categorical_accuracy: 0.0610 - val_factorized_top_k/top_50_categorical_accuracy: 0.4332 - val_factorized_top_k/top_100_categorical_accuracy: 0.9970 - val_loss: 2028.1292 - val_regularization_loss: 1.2042e-06 - val_total_loss: 2028.1292\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 39s 151ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0095 - factorized_top_k/top_5_categorical_accuracy: 0.0953 - factorized_top_k/top_10_categorical_accuracy: 0.1856 - factorized_top_k/top_50_categorical_accuracy: 0.6761 - factorized_top_k/top_100_categorical_accuracy: 0.9981 - loss: 4977.9069 - regularization_loss: 1.1821e-06 - total_loss: 4977.9069 - val_factorized_top_k/top_1_categorical_accuracy: 0.0010 - val_factorized_top_k/top_5_categorical_accuracy: 0.0193 - val_factorized_top_k/top_10_categorical_accuracy: 0.0512 - val_factorized_top_k/top_50_categorical_accuracy: 0.4165 - val_factorized_top_k/top_100_categorical_accuracy: 0.9915 - val_loss: 2064.4592 - val_regularization_loss: 1.2351e-06 - val_total_loss: 2064.4592\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 40s 153ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0082 - factorized_top_k/top_5_categorical_accuracy: 0.0973 - factorized_top_k/top_10_categorical_accuracy: 0.1930 - factorized_top_k/top_50_categorical_accuracy: 0.6939 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 4964.2064 - regularization_loss: 1.2082e-06 - total_loss: 4964.2064 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0172 - val_factorized_top_k/top_10_categorical_accuracy: 0.0481 - val_factorized_top_k/top_50_categorical_accuracy: 0.4057 - val_factorized_top_k/top_100_categorical_accuracy: 0.9936 - val_loss: 2094.7778 - val_regularization_loss: 1.2612e-06 - val_total_loss: 2094.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x2885caa2fb0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================\n",
    "# 2. TF Dataset\n",
    "# ====================\n",
    "interaction_df[\"user_id\"] = interaction_df[\"user_id\"].astype(str)\n",
    "interaction_df[\"title\"] = interaction_df[\"title\"].astype(str)\n",
    "\n",
    "unique_user_ids = interaction_df[\"user_id\"].unique()\n",
    "unique_titles = interaction_df[\"title\"].unique()\n",
    "\n",
    "train_df, test_df = train_test_split(interaction_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": train_df[\"user_id\"],\n",
    "    \"title\": train_df[\"title\"]\n",
    "}).shuffle(100).batch(768).cache()\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": test_df[\"user_id\"].values,\n",
    "    \"title\": test_df[\"title\"].values,\n",
    "    \"rating\": test_df[\"rating\"].values,\n",
    "}).batch(512)\n",
    "\n",
    "recipe_dataset = tf.data.Dataset.from_tensor_slices(unique_titles)\n",
    "\n",
    "# ====================\n",
    "# 3. Lookup Layers\n",
    "# ====================\n",
    "user_lookup = tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None)\n",
    "title_lookup = tf.keras.layers.StringLookup(vocabulary=unique_titles, mask_token=None)\n",
    "\n",
    "# ====================\n",
    "# 4. User & Item Model dengan Dense tambahan\n",
    "# ====================\n",
    "embedding_dim = 512\n",
    "\n",
    "def diversity_loss(embeddings):\n",
    "    normed = tf.math.l2_normalize(embeddings, axis=1)\n",
    "    cosine_sim = tf.matmul(normed, normed, transpose_b=True)\n",
    "    identity = tf.eye(tf.shape(cosine_sim)[0])\n",
    "    diff = cosine_sim - identity\n",
    "    return tf.reduce_mean(tf.abs(diff))\n",
    "\n",
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            user_lookup,\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim=len(unique_user_ids) + 1,\n",
    "                output_dim=embedding_dim,\n",
    "                activity_regularizer=tf.keras.regularizers.l2(1e-6)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(embedding_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.user_embedding(inputs)\n",
    "\n",
    "class ItemModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            title_lookup,\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim=len(unique_titles) + 1,\n",
    "                output_dim=embedding_dim,\n",
    "                activity_regularizer=tf.keras.regularizers.l2(1e-6)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(embedding_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.item_embedding(inputs)\n",
    "\n",
    "class RecipeModel(tfrs.Model):\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=recipe_dataset.batch(128).map(lambda x: (x, item_model(x)))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        item_embeddings = self.item_model(features[\"title\"])\n",
    "        main_loss = self.task(user_embeddings, item_embeddings)\n",
    "        div_loss = diversity_loss(item_embeddings)\n",
    "        return main_loss + 0.001 * div_loss\n",
    "\n",
    "user_model = UserModel()\n",
    "item_model = ItemModel()\n",
    "model = RecipeModel(user_model, item_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0005))\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=[early_stop])\n",
    "\n",
    "# Bangun ulang index dengan model yang baru\n",
    "indexed_dataset = recipe_dataset.map(lambda title: (tf.expand_dims(title, 0), item_model(tf.expand_dims(title, 0))))\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(indexed_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d97c40e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resep yang telah diberi rating oleh user user_3:\n",
      "- Mexican Cookie Rings (Rating: 5)\n",
      "- Taco-Filled Green Pepper (Rating: 5)\n",
      "- Cheese Dip (Rating: 5)\n",
      "- Brown Rice (Rating: 4)\n",
      "- Pink Stuff(Frozen Dessert)   (Rating: 5)\n",
      "- Millionaire Pie (Rating: 4)\n",
      "- Angel Biscuits (Rating: 5)\n",
      "- Chocolate Frango Mints (Rating: 5)\n",
      "- Sausage Balls (Rating: 4)\n",
      "- Chicken Roll-Ups (Rating: 5)\n",
      "- Fruit Pizza (Rating: 5)\n",
      "- Corral Barbecued Beef Steak Strips (Rating: 4)\n",
      "- Forever Amber (Rating: 4)\n",
      "- Quick Barbecue Wings (Rating: 4)\n",
      "- Grandma Hanrath'S Banana Breadfort Collins, Colorado   (Rating: 4)\n",
      "- Beer Bread (Rating: 5)\n",
      "- Chocolate Mint Bars (Rating: 5)\n",
      "- Chicken Stew (Rating: 4)\n",
      "- Taco Salad Chip Dip (Rating: 3)\n",
      "- Gooey Coffee Cake (Rating: 5)\n",
      "- Three Bean Salad (Rating: 5)\n",
      "- Chicken Ole (Rating: 5)\n",
      "- Potato Casserole (Rating: 5)\n",
      "- Beef And Spanish Rice Casserole (Rating: 3)\n",
      "- Crab Cakes (Rating: 4)\n",
      "- Cheeseburger Potato Soup (Rating: 4)\n",
      "- Chicken Funny (Rating: 4)\n",
      "- Scalloped Corn (Rating: 2)\n",
      "- Cranberry Salad (Rating: 5)\n",
      "- Spanish Hamburgers (Rating: 5)\n",
      "- Phylis' Pineapple-Banana Salad (Rating: 4)\n",
      "- Potato And Cheese Pie (Rating: 4)\n",
      "- Annie'S Diabetic Candy (Rating: 4)\n",
      "- Cranberry-Apple-Orange Salad (Rating: 4)\n",
      "- Squash Casserole (Rating: 1)\n",
      "- Funnel Cake (Rating: 4)\n",
      "- Chicken Divan (Rating: 4)\n",
      "- Egg Casserole (Rating: 1)\n",
      "- Fast Real Good Fudge (Rating: 2)\n",
      "- Nolan'S Pepper Steak (Rating: 3)\n",
      "- Monkey Bread (Rating: 4)\n",
      "- Broccoli Dip For Crackers (Rating: 5)\n",
      "- Reeses Cups(Candy)   (Rating: 5)\n",
      "- Buckeye Candy (Rating: 4)\n",
      "- Bonbon Cookies (Rating: 4)\n",
      "- Brickle Bars (Rating: 5)\n",
      "- Smothered Round Steak(Servings: 4)   (Rating: 5)\n",
      "- Egg Drop Soup (Rating: 4)\n",
      "- Rhubarb Coffee Cake (Rating: 4)\n",
      "- Tuna Macaroni Casserole (Rating: 5)\n",
      "\n",
      "Rekomendasi untuk user user_3 (resep yang belum di-rate):\n",
      "- Artichoke Dip (Skor: 4.2778)\n",
      "- Sesame Ginger Chicken (Skor: 4.2348)\n",
      "- No-Bake Nut Cookies (Skor: 4.2191)\n",
      "- Eggless Milkless Applesauce Cake (Skor: 4.1990)\n",
      "- Creole Flounder (Skor: 4.1959)\n",
      "- Broccoli Salad (Skor: 4.1952)\n",
      "- Dream Pie (Skor: 4.1945)\n",
      "- Sweet-N-Sour Chicken (Skor: 4.1922)\n",
      "- Easy Fudge (Skor: 4.1855)\n",
      "- Mulled Cider (Skor: 4.1840)\n",
      "- Double Cherry Delight (Skor: 4.1828)\n",
      "- One Hour Rolls (Skor: 4.1823)\n",
      "- Cherry Pizza (Skor: 4.1817)\n",
      "- Watermelon Rind Pickles (Skor: 4.1802)\n",
      "- Spaghetti Sauce To Can (Skor: 4.1769)\n",
      "- Divinity Fudge (Skor: 4.1768)\n",
      "- Blueberry Surprise (Skor: 4.1768)\n",
      "- Strawberry Whatever (Skor: 4.1743)\n",
      "- Jewell Ball'S Chicken (Skor: 4.1683)\n",
      "- Cheese Ball (Skor: 4.1679)\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# 9. Contoh Penggunaan\n",
    "# ====================\n",
    "user_id = \"user_3\"  # Pastikan ID dalam format string dan cocok dengan user_lookup\n",
    "user_interactions = interaction_df[interaction_df[\"user_id\"] == user_id]\n",
    "\n",
    "print(f\"Resep yang telah diberi rating oleh user {user_id}:\")\n",
    "for _, row in user_interactions.iterrows():\n",
    "    print(f\"- {row['title']} (Rating: {row['rating']})\")\n",
    "\n",
    "# Set judul yang sudah dikunjungi\n",
    "visited_titles = set(user_interactions[\"title\"].values)\n",
    "\n",
    "# Ambil rekomendasi dari model\n",
    "scores, titles = index(tf.constant([user_id]), k=50)\n",
    "\n",
    "print(f\"\\nRekomendasi untuk user {user_id} (resep yang belum di-rate):\")\n",
    "count = 0\n",
    "max_results = 20\n",
    "\n",
    "for score, title in zip(scores[0].numpy(), titles[0].numpy()):\n",
    "    title_str = title.decode(\"utf-8\")\n",
    "    if title_str in visited_titles:\n",
    "        continue\n",
    "    print(f\"- {title_str} (Skor: {score:.4f})\")\n",
    "    count += 1\n",
    "    if count >= max_results:\n",
    "        break\n",
    "\n",
    "if count == 0:\n",
    "    print(\"Tidak ada rekomendasi resep baru untuk ditampilkan.\")\n",
    "elif count < max_results:\n",
    "    print(f\"(Hanya {count} resep baru yang bisa direkomendasikan)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c0b68a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluasi sistem rekomendasi dengan model eksploratif:\n",
      "\n",
      "Top-10\n",
      "- Precision@10:   0.0896\n",
      "- Novelty@10:     6.6498\n",
      "- Coverage@10:    0.6000\n",
      "- Serendipity@10: 0.0061\n"
     ]
    }
   ],
   "source": [
    "# Hitung popularitas item\n",
    "item_popularity = Counter(interaction_df[\"title\"])\n",
    "total_interaction = sum(item_popularity.values())\n",
    "\n",
    "# Set item unik untuk Coverage\n",
    "all_items = set(interaction_df[\"title\"].unique())\n",
    "\n",
    "# Riwayat user untuk Serendipity\n",
    "user_history = interaction_df.groupby(\"user_id\")[\"title\"].apply(set).to_dict()\n",
    "\n",
    "# ====================\n",
    "# Precision@K\n",
    "# ====================\n",
    "def precision_at_k(k):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_dict = test_df.groupby(\"user_id\")[\"title\"].apply(set).to_dict()\n",
    "\n",
    "    for user_id, true_items in test_dict.items():\n",
    "        _, recommended = index(tf.constant([user_id]), k=k)\n",
    "        recommended_ids = set(title.numpy().decode(\"utf-8\") for title in recommended[0])\n",
    "        hits = recommended_ids.intersection(true_items)\n",
    "        correct += len(hits)\n",
    "        total += k\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# ====================\n",
    "# Novelty@K\n",
    "# ====================\n",
    "def novelty_at_k(k):\n",
    "    total_novelty = 0.0\n",
    "    total_users = 0\n",
    "\n",
    "    for user_id in test_df[\"user_id\"].unique():\n",
    "        _, recommended = index(tf.constant([user_id]), k=k)\n",
    "        novelty_score = 0.0\n",
    "        for title in recommended[0].numpy():\n",
    "            title_str = title.decode(\"utf-8\")\n",
    "            freq = item_popularity[title_str] / total_interaction\n",
    "            if freq > 0:\n",
    "                novelty_score += -np.log2(freq)\n",
    "        avg_novelty = novelty_score / k\n",
    "        total_novelty += avg_novelty\n",
    "        total_users += 1\n",
    "\n",
    "    return total_novelty / total_users if total_users > 0 else 0\n",
    "\n",
    "# ====================\n",
    "# Coverage@K\n",
    "# ====================\n",
    "def coverage_at_k(k):\n",
    "    recommended_items = set()\n",
    "    for user_id in test_df[\"user_id\"].unique():\n",
    "        _, recommended = index(tf.constant([user_id]), k=k)\n",
    "        for title in recommended[0].numpy():\n",
    "            recommended_items.add(title.decode(\"utf-8\"))\n",
    "    return len(recommended_items) / len(all_items)\n",
    "\n",
    "# ====================\n",
    "# Serendipity@K\n",
    "# ====================\n",
    "def serendipity_at_k(k):\n",
    "    serendipity_sum = 0.0\n",
    "    user_count = 0\n",
    "\n",
    "    for user_id in test_df[\"user_id\"].unique():\n",
    "        seen = user_history.get(user_id, set())\n",
    "        seen_vecs = []\n",
    "\n",
    "        for title in seen:\n",
    "            vec = model.item_model(tf.constant([title])).numpy()\n",
    "            seen_vecs.append(vec[0])\n",
    "\n",
    "        if not seen_vecs:\n",
    "            continue\n",
    "\n",
    "        seen_avg = np.mean(seen_vecs, axis=0).reshape(1, -1)\n",
    "\n",
    "        _, recommended = index(tf.constant([user_id]), k=k)\n",
    "        ser = 0\n",
    "\n",
    "        for title in recommended[0].numpy():\n",
    "            title_str = title.decode(\"utf-8\")\n",
    "            if title_str in seen:\n",
    "                continue\n",
    "            rec_vec = model.item_model(tf.constant([title_str])).numpy().reshape(1, -1)\n",
    "            sim = cosine_similarity(seen_avg, rec_vec)[0][0]\n",
    "            ser += 1 - sim\n",
    "\n",
    "        serendipity_sum += ser / k\n",
    "        user_count += 1\n",
    "\n",
    "    return serendipity_sum / user_count if user_count > 0 else 0\n",
    "\n",
    "# ====================\n",
    "# Evaluasi Semua Metrik\n",
    "# ====================\n",
    "def evaluate_model(k_values=[10]):\n",
    "    print(\"Evaluasi sistem rekomendasi dengan model eksploratif:\")\n",
    "    for k in k_values:\n",
    "        precision = precision_at_k(k)\n",
    "        novelty = novelty_at_k(k)\n",
    "        coverage = coverage_at_k(k)\n",
    "        serendipity = serendipity_at_k(k)\n",
    "        print(f\"\\nTop-{k}\")\n",
    "        print(f\"- Precision@{k}:   {precision:.4f}\")\n",
    "        print(f\"- Novelty@{k}:     {novelty:.4f}\")\n",
    "        print(f\"- Coverage@{k}:    {coverage:.4f}\")\n",
    "        print(f\"- Serendipity@{k}: {serendipity:.4f}\")\n",
    "\n",
    "# Jalankan evaluasi\n",
    "evaluate_model(k_values=[10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
